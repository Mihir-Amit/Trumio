{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9fkKQMY6-Iz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "num_entries = 10000\n",
        "def generate_time_percentages(num_entries):\n",
        "    percentages = np.random.dirichlet(np.ones(3), size=num_entries) * 100\n",
        "    return percentages\n",
        "time_percentages = generate_time_percentages(num_entries)\n",
        "dataset = pd.DataFrame({\n",
        "    'Hard Problem Solved': np.random.rand(num_entries),\n",
        "    'Medium Problem Solved': np.random.rand(num_entries),\n",
        "    'Easy Problem Solved': np.random.rand(num_entries),\n",
        "    'Time of the test spent on solving Hard questions': time_percentages[:, 0],\n",
        "    'Time of the test spent on solving Medium questions': time_percentages[:, 1],\n",
        "    'Time of the test spent on solving Easy questions': time_percentages[:, 2],\n",
        "    'Hardness level of each test': np.random.randint(1, 6, num_entries)\n",
        "})\n",
        "passing_criteria = {\n",
        "    1: (dataset['Easy Problem Solved'] > 0.8) & (dataset['Medium Problem Solved'] > 0.7) & (dataset['Hard Problem Solved'] > 0.6),\n",
        "    2: (dataset['Easy Problem Solved'] > 0.75) & (dataset['Medium Problem Solved'] > 0.65) & (dataset['Hard Problem Solved'] > 0.55),\n",
        "    3: (dataset['Easy Problem Solved'] > 0.65) & (dataset['Medium Problem Solved'] > 0.55) & (dataset['Hard Problem Solved'] > 0.5),\n",
        "    4: (dataset['Easy Problem Solved'] > 0.6) & (dataset['Medium Problem Solved'] > 0.5) & (dataset['Hard Problem Solved'] > 0.45),\n",
        "    5: (dataset['Easy Problem Solved'] > 0.55) & (dataset['Medium Problem Solved'] > 0.45) & (dataset['Hard Problem Solved'] > 0.4)\n",
        "}\n",
        "for level, criteria in passing_criteria.items():\n",
        "    dataset.loc[dataset['Hardness level of each test'] == level, 'Result'] = criteria.loc[criteria].astype(int)\n",
        "dataset['Result'] = dataset['Result'].fillna(0).astype(int)\n",
        "dataset.head(10)\n",
        "shuffled_df = dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "dataset = shuffled_df"
      ],
      "metadata": {
        "id": "qfRTeIZy7O_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE()\n",
        "X = dataset.drop('Result', axis=1)\n",
        "y = dataset['Result']\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "print('Original dataset shape %s' % Counter(y))\n",
        "print('Resampled dataset shape %s' % Counter(y_res))\n",
        "resampled_data = pd.DataFrame(X_res, columns=X.columns)\n",
        "resampled_data['Result'] = y_res\n",
        "resampled_data.head()\n",
        "resampled_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_xFZDiu7m10",
        "outputId": "50bd8034-9975-476a-b0cb-2469796c52bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape Counter({0: 9218, 1: 782})\n",
            "Resampled dataset shape Counter({1: 9218, 0: 9218})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18436, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "X = resampled_data.drop('Result', axis=1)\n",
        "y = resampled_data['Result']\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_cv, X_test, y_cv, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_cv_pred = logreg.predict(X_cv)\n",
        "print('Classification Report for Cross-Validation Set:')\n",
        "print(classification_report(y_cv, y_cv_pred))\n",
        "y_test_pred = logreg.predict(X_test)\n",
        "print('Classification Report for Test Set:')\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "print('Confusion Matrix for Test Set:')\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTpwSGJ8_iIS",
        "outputId": "8052f61b-df64-4b79-a6ab-b9f4b05ce1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Cross-Validation Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94      1829\n",
            "           1       0.92      0.96      0.94      1858\n",
            "\n",
            "    accuracy                           0.94      3687\n",
            "   macro avg       0.94      0.94      0.94      3687\n",
            "weighted avg       0.94      0.94      0.94      3687\n",
            "\n",
            "Classification Report for Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.89      0.92      1873\n",
            "           1       0.89      0.97      0.93      1815\n",
            "\n",
            "    accuracy                           0.93      3688\n",
            "   macro avg       0.93      0.93      0.93      3688\n",
            "weighted avg       0.93      0.93      0.93      3688\n",
            "\n",
            "Confusion Matrix for Test Set:\n",
            "[[1662  211]\n",
            " [  59 1756]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_cv_rf_pred = rf_model.predict(X_cv)\n",
        "gb_model.fit(X_train, y_train)\n",
        "y_cv_gb_pred = gb_model.predict(X_cv)\n",
        "rf_report = classification_report(y_cv, y_cv_rf_pred)\n",
        "gb_report = classification_report(y_cv, y_cv_gb_pred)\n",
        "print('Random Forest Classification Report for Cross-Validation Set:')\n",
        "print(rf_report)\n",
        "print('Gradient Boosting Classification Report for Cross-Validation Set:')\n",
        "print(gb_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OawtJaynBTbp",
        "outputId": "cdfb8ebb-cefa-4e1d-c84e-8a1a3b4ac613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classification Report for Cross-Validation Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99      1829\n",
            "           1       0.99      1.00      0.99      1858\n",
            "\n",
            "    accuracy                           0.99      3687\n",
            "   macro avg       0.99      0.99      0.99      3687\n",
            "weighted avg       0.99      0.99      0.99      3687\n",
            "\n",
            "Gradient Boosting Classification Report for Cross-Validation Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1829\n",
            "           1       0.98      1.00      0.99      1858\n",
            "\n",
            "    accuracy                           0.99      3687\n",
            "   macro avg       0.99      0.99      0.99      3687\n",
            "weighted avg       0.99      0.99      0.99      3687\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "voting_clf = VotingClassifier(estimators=[('lr', logreg), ('rf', rf_model), ('gb', gb_model)], voting='soft')\n",
        "voting_clf.fit(X_train, y_train)\n",
        "y_cv_ensemble_pred = voting_clf.predict(X_cv)\n",
        "ensemble_report = classification_report(y_cv, y_cv_ensemble_pred)\n",
        "print('Ensemble Method Classification Report for Cross-Validation Set:')\n",
        "print(ensemble_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvLax9XGBaAe",
        "outputId": "b052d26b-a1a8-434f-9862-b3a5282e241c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Method Classification Report for Cross-Validation Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1829\n",
            "           1       0.98      1.00      0.99      1858\n",
            "\n",
            "    accuracy                           0.99      3687\n",
            "   macro avg       0.99      0.99      0.99      3687\n",
            "weighted avg       0.99      0.99      0.99      3687\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.neural_network import MLPClassifier\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# file_path = '/content/Clustered_Student_Performance.csv'\n",
        "# data = pd.read_csv(file_path)\n",
        "# X = data[['Hardness of Skill Tested', 'Percentage of Hard Questions Correct', 'Percentage of Medium Questions Correct', 'Percentage of Easy Questions Correct', 'Accuracy on Hard Questions', 'Accuracy on Medium Questions', 'Accuracy on Easy Questions', 'Percentage of Time Left on Clock']]\n",
        "# y = data['Passed']\n",
        "\n",
        "# # Split the data into training and test sets (70% train, 30% test)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# # Initialize the MLPClassifier\n",
        "# mlp = MLPClassifier(random_state=42)\n",
        "\n",
        "# mlp.fit(X_train, y_train)\n",
        "\n",
        "# y_pred = mlp.predict(X_test)\n",
        "\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# print('Neural Network Model Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "mport pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "file_path = 'Clustered_Student_Performance.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "X = data[['Hardness of Skill Tested', 'Percentage of Hard Questions Correct', 'Percentage of Medium Questions Correct', 'Percentage of Easy Questions Correct', 'Accuracy on Hard Questions', 'Accuracy on Medium Questions', 'Accuracy on Easy Questions', 'Percentage of Time Left on Clock']].values\n",
        "y = data['Passed'].values\n",
        "\n",
        "y = to_categorical(y, num_classes=2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "accuracy = scores[1] * 100\n",
        "\n",
        "print('Neural Network Model Accuracy with TensorFlow/Keras: {:.2f}%'.format(accuracy))"
      ],
      "metadata": {
        "id": "spvnbfUUabPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Extracting true positives, true negatives, false positives, and false negatives\n",
        "true_positive = conf_matrix[1, 1]\n",
        "true_negative = conf_matrix[0, 0]\n",
        "false_positive = conf_matrix[0, 1]\n",
        "false_negative = conf_matrix[1, 0]\n",
        "\n",
        "# Print the values\n",
        "print('True Positives:', true_positive)\n",
        "print('True Negatives:', true_negative)\n",
        "print('False Positives:', false_positive)\n",
        "print('False Negatives:', false_negative)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16FWQhPpbfFc",
        "outputId": "dfb2f497-e970-4495-c93e-cf3ed11d8678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Positives: 610\n",
            "True Negatives: 2228\n",
            "False Positives: 31\n",
            "False Negatives: 131\n"
          ]
        }
      ]
    }
  ]
}